# Writing Good Geists: A Practical Guide

**Purpose**: This guide helps you write geists that embody GeistFabrik's philosophy of "muses, not oracles."

---

## Core Philosophy

> "GeistFabrik is not an answer machine—it's a **question factory**."

Your geist should:
- ✅ **Ask questions**, not give answers
- ✅ **Provoke**, not prescribe
- ✅ **Surprise**, not predict
- ✅ **Diverge**, not converge
- ✅ Ask **different questions** than users would ask themselves

---

## The Golden Rules

### Rule 1: Questions, Not Commands

**❌ Bad** (prescriptive):
```python
"You should expand [[{note}]]. It's underdeveloped."
"Consider linking [[{note_a}]] to [[{note_b}]]."
"This note needs more connections."
```

**✅ Good** (provocative):
```python
"What if [[{note}]]'s brevity is intentional—a hinge concept that gains power from compression?"
"What if [[{note_a}]] and [[{note_b}]] were connected? What would emerge?"
"[[{note}]] has few links. Self-contained island or overlooked hub?"
```

**Key difference**: Good geists raise possibilities; bad geists give instructions.

---

### Rule 2: Speculative, Not Certain

**❌ Bad** (judgmental):
```python
"[[{note}]] is wrong."
"This connection doesn't make sense."
"You've made an error in [[{note}]]."
```

**✅ Good** (speculative):
```python
"What if [[{note}]] is only half the story?"
"[[{note_a}]] and [[{note_b}]] seem to contradict each other—what gives?"
"I think you're lying about your claim in [[{note}]]..." (playful provocation)
```

**Key words**: Use "might", "could", "what if", "perhaps" - never "must", "should", "needs to".

---

### Rule 3: Vault-Specific, Not Generic

**❌ Bad** (could apply to any vault):
```python
f"Why is {title}?"  # Generic question anyone would ask
f"How does {title} work?"  # Too obvious
"What if you thought about creativity?"  # Not grounded in vault
```

**✅ Good** (uses actual vault relationships):
```python
"[[{note_a}]] and [[{note_b}]] are semantically similar (0.87) despite no links. Same pattern, different scale?"
"[[{note}]] has been interpreted differently across your last 5 sessions—meaning unsettled?"
"Your Q2 notes cluster around [[Flow]], but Q4 notes cluster around [[Structure]]. Different seasons?"
```

**Key difference**: Reference specific notes, relationships, and patterns in the user's actual vault.

---

### Rule 4: Multiple Interpretations

**❌ Bad** (only one answer):
```python
"[[{note}]] is too short. You should expand it."  # One obvious action
```

**✅ Good** (many possible responses):
```python
"[[{note}]] has only 47 words but 8 backlinks. What if its brevity is intentional? Or is it waiting to emerge?"
# Could interpret as: 1) intentionally minimal, 2) needs expansion, 3) serves as connector, etc.
```

**Key difference**: Good questions open up thinking; bad questions narrow it down.

---

## Writing Patterns That Work

### Pattern 1: "What if" Questions
The most reliable pattern for provocative suggestions.

```python
"What if [[{note_a}]] and [[{note_b}]] were connected?"
"What if you zoomed in on [[{abstract_note}]]?"
"What if [[{note}]]'s contradictions are actually revealing something?"
```

### Pattern 2: Contrasting Observations
Point out patterns and let users interpret them.

```python
"[[{note}]] has high link density (0.15), while [[{other}]] has low density (0.02).
Connector vs. island?"
```

### Pattern 3: Temporal Awareness
Track changes over time without prescribing action.

```python
"Your understanding of [[{note}]] shifted between sessions,
even though you haven't edited it in 127 days. What changed?"
```

### Pattern 4: Provocative Framing
Use playful or challenging framing to spark engagement.

```python
"I think you're lying about your claim in [[{note}]] because..." (Columbo-style)
"What would the opposite of [[{note}]] look like?"
"Who would disagree with [[{note}]]?"
```

### Pattern 5: Either/Or Questions
Offer contrasting interpretations.

```python
"[[{note}]] is brief but referenced often. Hinge concept or placeholder?"
"Current preoccupation or emerging theme?"
"Deep focus or narrowing perspective?"
```

---

## Anti-Patterns to Avoid

### Anti-Pattern 1: The Todo List
```python
# ❌ Don't turn geists into task managers
"You should expand [[{note}]]."
"Consider adding more links."
"This needs revision."
```

**Fix**: Ask what the current state reveals, don't prescribe changes.

---

### Anti-Pattern 2: The Linter
```python
# ❌ Don't give code-review style feedback
"[[{note}]] has too many links. Consider focusing on key connections."
"This note is too short for its importance."
"Poor link density detected."
```

**Fix**: Describe patterns and ask what they mean, don't judge them.

---

### Anti-Pattern 3: The Generic Template
```python
# ❌ Don't ask questions anyone would ask
f"Why is {title}?"  # Too obvious
f"How does {title} work?"  # Too generic
f"What is {title} about?"  # Not provocative
```

**Fix**: Use vault relationships to generate unexpected questions.

---

### Anti-Pattern 4: The Instruction Manual
```python
# ❌ Don't explain or educate
"Questions invite exploration where statements invite acceptance."
"Linking notes helps create connections."
"Writing regularly improves thinking."
```

**Fix**: Show, don't tell. Let the suggestion itself embody the principle.

---

## The "Would You Ask This Yourself?" Test

Before finalizing a geist, ask:

1. **Would I naturally think to ask this question?**
   - If yes → too generic, make it more specific/unexpected
   - If no → good, it's divergent

2. **Does this tell me what to do, or make me think?**
   - If "what to do" → too prescriptive, reframe as question
   - If "make me think" → good, it's provocative

3. **Could this apply to any vault, or is it specific to mine?**
   - If "any vault" → add specific note references
   - If "specific" → good, it's grounded

4. **Does this have one obvious answer, or multiple interpretations?**
   - If "one answer" → open it up with alternatives
   - If "multiple" → good, it's divergent

---

## Gold Standard Examples

Study these geists for excellent patterns:

### Columbo (Provocative Challenger)
```python
"I think you're lying about your claim in [[{note.title}]]
because [[{other.title}]] argues something that seems to contradict it"
```
**Why it's gold**: Playful, specific, catches user in contradictions they wouldn't notice.

---

### Session Drift (Metacognitive Mirror)
```python
"Your understanding of [[{note}]] shifted significantly between sessions.
What changed in how you're reading it?"
```
**Why it's gold**: Questions interpretation, not content. Reveals temporal evolution.

---

### Scale Shifter (Perspective Transformer)
```python
"[[{note}]] operates at high abstraction. What if you zoomed in?
[[{example}]] might be a more concrete instance."
```
**Why it's gold**: Suggests perspective shift, uses "might", connects specific notes.

---

### Assumption Challenger (Socratic Questioner)
```python
"[[{note}]] makes claims that seem certain,
but [[{other}]] expresses uncertainty.
What assumptions underlie the certainty?"
```
**Why it's gold**: Points out pattern, asks "what" not "you should".

---

## Practical Checklist

Before committing your geist, verify:

- [ ] Uses "what if" or question framing (not directives)
- [ ] Employs speculative language: "might", "could", "perhaps"
- [ ] References specific vault notes (not abstract concepts)
- [ ] Asks questions with multiple possible interpretations
- [ ] Provokes thinking rather than prescribing action
- [ ] Would surprise the user (not obvious questions)
- [ ] No directive verbs: "should", "consider", "must", "need to"
- [ ] No value judgments: "too many", "not enough", "wrong"
- [ ] Tone is playful or curious (not authoritative)

---

## Writing Process

### 1. Start With the Pattern
First, identify what your geist detects:
- Contradictions between notes?
- Temporal changes in understanding?
- Structural patterns in the graph?
- Semantic relationships?

### 2. Gather Vault Context
Collect specific information:
- Note titles, not just abstract categories
- Actual relationships (similarity scores, link counts, etc.)
- Temporal data (days since modified, session changes)

### 3. Draft Multiple Framings
Try different approaches:
```python
# Version 1: Direct question
"What if [[{note_a}]] and [[{note_b}]] contradict each other?"

# Version 2: Provocative framing
"I think you're lying about [[{note_a}]] because [[{note_b}]]..."

# Version 3: Either/or
"[[{note_a}]] and [[{note_b}]] seem opposed. Contradiction or complementary?"
```

### 4. Apply the "Would I Ask This?" Test
Pick the version that:
- You wouldn't naturally think of
- Makes you curious rather than obligated
- Opens up rather than narrows down

### 5. Remove Prescriptive Language
Edit out:
- "you should", "consider", "must"
- "worth doing", "needs", "requires"
- "too much", "not enough"

Replace with:
- "what if", "might", "could"
- Questions, not statements
- Observations, not judgments

---

## Language Reference

### ✅ Use These
- "What if..."
- "might", "could", "perhaps"
- "seems", "appears"
- "?" (questions)
- "or" (alternatives)
- Specific note titles: [[{note}]]
- Concrete numbers: "5 links", "127 days"

### ❌ Avoid These
- "you should", "consider"
- "must", "need to", "have to"
- "too much", "not enough"
- "worth", "important", "critical"
- "." (declarative statements)
- Generic abstractions: "creativity", "learning"
- Commands: "expand", "link", "revise"

---

## Examples: Before & After

### Example 1: Stub Expander

**❌ Before** (prescriptive):
```python
"What if you expanded [[{note}]]? It's only {words} words but has {links} connections.
This stub might be worth developing."
```

**✅ After** (provocative):
```python
"[[{note}]] has only {words} words but {links} notes reference it.
What if its brevity is intentional—a hinge gaining power from compression?
Or is it a placeholder waiting to emerge?"
```

---

### Example 2: Link Density

**❌ Before** (linter-style):
```python
"[[{note}]] has too many links ({count} in {words} words).
Consider focusing on key connections."
```

**✅ After** (observational):
```python
"[[{note}]] has high link density ({density:.2f} per 100 words).
Is this a rhizome concept spreading through your vault?
Or is the density obscuring which connections actually matter?"
```

---

### Example 3: Question Generator

**❌ Before** (generic template):
```python
f"What if you reframed [[{title}]] as a question: 'Why is {title}?'"
```

**✅ After** (vault-specific):
```python
"[[{question_note}]] has been sitting as a question for {days} days.
What if [[{similar[0]}]], [[{similar[1]}]], and [[{similar[2]}]]
are actually partial answers you already have?"
```

---

## Advanced Techniques

### Technique 1: Columbo Mode
Frame findings as detective work, using playful confrontation:
```python
"I think you're lying about..."
"Something doesn't add up in..."
"You claim X in [[note_a]], but [[note_b]] suggests Y..."
```

### Technique 2: Temporal Framing
Emphasize change over time:
```python
"Your understanding of X shifted between sessions..."
"You wrote about Y in Q2, but Z in Q4..."
"X has been sitting unchanged for N days, but..."
```

### Technique 3: Scale Shifting
Suggest zooming in/out:
```python
"What if you zoomed in on [[abstract_note]]?"
"What if you zoomed out from [[specific_note]]?"
"X is concrete; what's the abstract pattern?"
```

### Technique 4: Dialectical Framing
Use thesis/antithesis/synthesis:
```python
"X and Y seem opposed. What would their synthesis be?"
"What's the antithesis of X?"
"X challenges Y—what reconciles them?"
```

---

## Performance Guidance

Writing good geists isn't just about philosophy—it's also about performance. Geists run within a 30-second timeout (default) and compete with 46 other geists for user attention. This section covers performance best practices learned from production use.

### Understanding the Timeout

**Default timeout**: 30 seconds per geist
- Configurable via `--timeout` flag during testing/development
- After 3 consecutive timeouts, geist is automatically disabled
- Timeout logged with test command for reproduction

**What happens on timeout**:
```
⚠ scale_shifter timed out (30.0s)
→ Test: geistfabrik test scale_shifter /path/to/vault --date YYYY-MM-DD
```

**Timeout budget breakdown** (typical 500-note vault):
- Embeddings & setup: ~0.5s (handled by session, not your geist)
- Your geist execution: 30.0s
- Filtering pipeline: ~0.2s per geist

### Common Performance Issues

#### Issue 1: O(N²) or O(N³) Operations

**❌ Problem**:
```python
# O(N²): Checking every pair
for note_a in notes:
    for note_b in notes:
        if vault.links_between(note_a, note_b):  # O(N) per call!
            # ...process pair...
```

**✅ Solution**: Build lookup structures once
```python
# O(N): Build link set once for O(1) lookups
link_pairs = set()
for note in notes:
    for target in vault.outgoing_links(note):
        pair = tuple(sorted([note.path, target.path]))
        link_pairs.add(pair)

# Now O(1) per lookup
for note_a in notes:
    for note_b in notes:
        pair = tuple(sorted([note_a.path, note_b.path]))
        if pair in link_pairs:
            # ...process pair...
```

**Real-world impact**: pattern_finder improved from O(N³) to O(N) using this technique, gaining 30-50% speedup on 10k vaults.

#### Issue 2: Redundant Similarity Computations

**❌ Problem**:
```python
# Calls batch_similarity() which bypasses session cache
similarities = vault.batch_similarity(note, candidates)
```

**✅ Solution**: Use individual similarity() calls
```python
# Each call hits session-scoped cache if already computed
for candidate in candidates:
    sim = vault.similarity(note, candidate)
    if sim > threshold:
        # ...process pair...
```

**Why this matters**: Other geists may have already computed these similarities in the same session. Individual `similarity()` calls leverage the cache; `batch_similarity()` does not.

**Real-world impact**: Phase 3B rollback showed scale_shifter using batch operations caused cache misses, losing 15-25% speedup potential.

#### Issue 3: Excessive Clustering Operations

**❌ Problem**:
```python
# Running full clustering on every invocation
from sklearn.cluster import AgglomerativeClustering
clusters = AgglomerativeClustering(n_clusters=10).fit(embeddings)
```

**✅ Solution**: Use sampling and similarity checks
```python
# Lightweight clustering via sampling
seed = vault.sample(notes, k=1)[0]
cluster = [seed]
for note in vault.sample(notes, min(100, len(notes))):
    if vault.similarity(seed, note) > 0.7:
        cluster.append(note)
        if len(cluster) >= 5:
            break
```

**Why this matters**: Full sklearn clustering takes 2-10 seconds on 1000+ note vaults. Sampling with similarity checks takes <1 second.

#### Issue 4: Sampling at Fixed Size

**❌ Problem**:
```python
# Fixed 500-note sample loses 95% coverage on 10k vaults
sampled = vault.sample(notes, k=500)
for note in sampled:
    # ...analyze note...
```

**❌ Also problematic**:
```python
# Processes ALL notes, timeouts on large vaults
for note in notes:
    # ...expensive operation per note...
```

**✅ Solution**: Adaptive sampling
```python
# Scale sample size with vault size
sample_size = min(1000, max(50, len(notes) // 10))
sampled = vault.sample(notes, k=sample_size)
for note in sampled:
    # ...analyze note...
```

**Or**: Process all notes efficiently
```python
# If operation is O(1) or O(log N) per note, process all
for note in notes:
    # ...cheap operation like word counting...
```

**Real-world impact**: Phase 3B pattern_finder used fixed 500-note sampling, missing 95% of patterns on large vaults. Reverting to full processing with O(N) optimization was faster AND more accurate.

### Phase 3B Lessons Learned

**Three key lessons from the Phase 3B rollback** (see `docs/POST_MORTEM_PHASE3B.md` for full analysis):

1. **Profile first, optimize second**
   - Sampling introduced to "improve performance" without profiling
   - Reality: Phrase extraction was the bottleneck (67.7% of time), not corpus iteration
   - Lesson: Measure before optimizing; intuition misleads

2. **Respect the session cache**
   - `batch_similarity()` bypassed session-scoped similarity cache
   - Other geists had already computed those similarities
   - Lesson: Individual `similarity()` calls > batch calls when cache is warm

3. **Quality > Speed**
   - pattern_finder sampling saved ~20s but lost 95% pattern coverage
   - Suggestions quality dropped, users got worse experience
   - Lesson: A slightly slower geist that works > fast geist that doesn't

**Rollback stats**:
- pattern_finder: Removed sampling, restored 95% coverage, acceptable performance
- scale_shifter: Reverted batch_similarity to individual calls, gained cache benefits
- Both geists: Quality improved, performance acceptable

### Development Workflow for Performance

1. **Start with correctness**
   ```bash
   # Test on small vault first
   uv run geistfabrik test my_geist testdata/kepano-obsidian-main/
   ```

2. **Test on large vaults**
   ```bash
   # Use higher timeout during development
   uv run geistfabrik test my_geist /path/to/1000-note-vault --timeout 30
   ```

3. **Profile if needed**
   ```python
   import cProfile
   import pstats

   profiler = cProfile.Profile()
   profiler.enable()

   # Your geist logic here

   profiler.disable()
   stats = pstats.Stats(profiler)
   stats.sort_stats('cumulative')
   stats.print_stats(20)
   ```

4. **Optimize bottlenecks only**
   - Don't optimize until you've identified the actual bottleneck
   - Focus on algorithmic improvements (O(N³) → O(N)) before micro-optimizations

5. **Verify improvements**
   ```bash
   # Compare before/after with timing
   time uv run geistfabrik test my_geist /large-vault --timeout 30
   ```

### When NOT to Optimize

**Don't optimize if**:
- Your geist completes in <2 seconds on 1000-note vaults
- You haven't profiled to find the bottleneck
- Optimization would reduce suggestion quality
- The geist only runs on small sample sizes anyway

**Example**: A geist that samples 10 notes and analyzes them doesn't need optimization, even if analysis is O(N²)—because N=10.

**Remember**: GeistFabrik's filtering pipeline runs AFTER your geist. If your geist returns 100 suggestions but filtering reduces it to 2, the user only sees 2. Quality of those 2 matters more than speed of generating 100.

### Performance Checklist

Before committing your geist, verify:

- [ ] Completes in <5s on 500-note vault (test on `testdata/kepano-obsidian-main/`)
- [ ] Completes in <30s on 1000-note vault (if you have one available)
- [ ] Uses `similarity()` not `batch_similarity()` when cache might be warm
- [ ] Builds lookup structures (sets, dicts) instead of O(N) repeated searches
- [ ] Avoids sklearn clustering unless absolutely necessary
- [ ] Uses adaptive sampling if sampling at all: `min(N, max(50, len(notes)//10))`
- [ ] Early terminates when enough suggestions found (5-10 is plenty)
- [ ] Hasn't been optimized prematurely (profile first!)

### Performance Resources

- **Study these performant geists**:
  - `pattern_finder.py` - O(N³) → O(N) optimization via link set
  - `scale_shifter.py` - Individual similarity calls for cache benefits
  - `bridge_hunter.py` - Early termination after 2 suggestions

- **Read these documents**:
  - `docs/POST_MORTEM_PHASE3B.md` - Detailed rollback analysis with lessons
  - `tests/integration/test_phase3b_regression.py` - Regression tests preventing future issues

- **Profile your geist**:
  ```bash
  # Run with debug timing
  uv run geistfabrik invoke /path/to/vault --geist my_geist --timeout 30 --debug
  ```

---

## Common Questions

### Q: Can I ever use directive language?
**A**: Rarely. If you do, it should be playful/provocative, not authoritative:
- ✅ "I think you're lying about..." (playful challenge)
- ❌ "You should link these notes" (authoritative command)

### Q: What if my geist genuinely finds an error?
**A**: Frame it as a question, not a correction:
- ❌ "[[note]] has an error"
- ✅ "[[note_a]] and [[note_b]] seem to contradict—what gives?"

### Q: Can I suggest creating a new note?
**A**: Yes, but make it speculative:
- ❌ "You should create a synthesis note"
- ✅ "What would a synthesis between X and Y look like?"

### Q: How specific should I be?
**A**: Very. Reference actual note titles, specific numbers, concrete relationships.

### Q: What about Tracery geists?
**A**: Same principles apply. Use vault functions ($vault.sample_notes, etc.) to ground abstract templates in specific vault content.

---

## Getting Feedback

Test your geist by asking others:
1. **Does this feel like advice or a question?**
2. **Would you naturally think to ask this yourself?**
3. **Does this make you curious or obligated?**
4. **Is this specific to a vault or generic?**

If answers are "advice", "yes I'd ask this", "obligated", "generic" → revise.

---

## Resources

- **Study these exemplary geists**:
  - `columbo.py` - Gold standard for provocative questioning
  - `session_drift.py` - Excellent temporal framing
  - `assumption_challenger.py` - Great Socratic style
  - `scale_shifter.py` - Superb perspective shifting

- **Read these documents**:
  - `AMBITIOUS_GEISTS.md` - Philosophy and examples
  - `specs/geistfabrik_vision.md` - Core principles
  - `docs/audits/GEIST_AUDIT.md` - Detailed analysis of all geists

- **Audit tool** (coming soon):
  ```bash
  geistfabrik validate --geist my_geist
  ```

---

## Final Wisdom

> "The owl of Minerva spreads its wings only with the falling of the dusk." — Hegel

Like Hegel's owl, geists work retrospectively—finding patterns and questions in knowledge already accumulated. They are **spirits in a factory of thought**, not managers of a to-do list.

Your geist should ask: **"What if?"** not **"You should."**

It should be a **muse**, not an **oracle**.

Most importantly, it should ask **different questions than users would ask themselves**—because that's the whole point of a divergence engine.

---

**Happy geist writing!**
